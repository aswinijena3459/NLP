{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization is a process of breaking down a given paragraph of text into a list of sentence or words. When paragraph is broken down into list of sentences, it is called sentence tokenization. Similarly, if the sentences are further broken down into list of words, it is known as Word tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### punkt is a nltk library tool for tokenizing text documents. When we use an old or a degraded version of nltk module we generally need to download the remaining data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('corpus')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizing using nltk library\n",
    "import nltk\n",
    "data=\"The Mapogo coalition originated from Mala Mala from what was called the “Eyrefield Pride” (Sparta Pride) and moved into the Western Sector in 2006. The Mapogo lions followed a recent trend in the Sabi Sand Reserve of mega pride male lion coalitions. The five related brothers were sired by a similar mega pride coalition of five male lions.[4] In their quest to dominate the area, the six lions killed approximately 40 other lions which included many cubs, females, and rival adult males.[5].The oldest Mapogo male, Makulu, is believed to be unrelated to the other five lions. The story is that the original Sparta pride lost a male sub-adult of 20 to 21 months of age in May/June 2000 and in July 2000, this male of about the same age latched on to the original pride. As a result, Makulu was naturally bigger in size than his fellow brothers.[6] Though not readily accepted by the lionesses, the West Street Males tolerated him and didn't kill him, even though typically, intruding males of his age would be chased off or killed. Field experts believe a likely reason for his acceptance into the pride was because he may have been the offspring of one of the West Street Males and a lioness from another pride (therefore making him the Mapogos' half brother).[7].In the first months of 2006, the five subadult lions and Makulu left their pride. They now had to fight for themselves, but by sticking together they increased their survival chances. Whilst living among themselves, the lions learned to be successful hunters. As they grew in size and experience, they were able to take down large prey such as hippos, young rhinos, and even giraffes. According to Dave Salmoni, successfully taking down cape buffalo was their 'key to success'. During the buffalo hunts, Kinky Tail (also called Shaka) and Mr. T (also called Satan) were often observed being more aggressive in bringing down the buffalo.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Mapogo coalition originated from Mala Mala from what was called the “Eyrefield Pride” (Sparta Pride) and moved into the Western Sector in 2006.',\n",
       " 'The Mapogo lions followed a recent trend in the Sabi Sand Reserve of mega pride male lion coalitions.',\n",
       " 'The five related brothers were sired by a similar mega pride coalition of five male lions.',\n",
       " '[4] In their quest to dominate the area, the six lions killed approximately 40 other lions which included many cubs, females, and rival adult males.',\n",
       " '[5].The oldest Mapogo male, Makulu, is believed to be unrelated to the other five lions.',\n",
       " 'The story is that the original Sparta pride lost a male sub-adult of 20 to 21 months of age in May/June 2000 and in July 2000, this male of about the same age latched on to the original pride.',\n",
       " 'As a result, Makulu was naturally bigger in size than his fellow brothers.',\n",
       " \"[6] Though not readily accepted by the lionesses, the West Street Males tolerated him and didn't kill him, even though typically, intruding males of his age would be chased off or killed.\",\n",
       " \"Field experts believe a likely reason for his acceptance into the pride was because he may have been the offspring of one of the West Street Males and a lioness from another pride (therefore making him the Mapogos' half brother).\",\n",
       " '[7].In the first months of 2006, the five subadult lions and Makulu left their pride.',\n",
       " 'They now had to fight for themselves, but by sticking together they increased their survival chances.',\n",
       " 'Whilst living among themselves, the lions learned to be successful hunters.',\n",
       " 'As they grew in size and experience, they were able to take down large prey such as hippos, young rhinos, and even giraffes.',\n",
       " \"According to Dave Salmoni, successfully taking down cape buffalo was their 'key to success'.\",\n",
       " 'During the buffalo hunts, Kinky Tail (also called Shaka) and Mr. T (also called Satan) were often observed being more aggressive in bringing down the buffalo.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(data)  ### sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Mapogo',\n",
       " 'coalition',\n",
       " 'originated',\n",
       " 'from',\n",
       " 'Mala',\n",
       " 'Mala',\n",
       " 'from',\n",
       " 'what',\n",
       " 'was',\n",
       " 'called',\n",
       " 'the',\n",
       " '“',\n",
       " 'Eyrefield',\n",
       " 'Pride',\n",
       " '”',\n",
       " '(',\n",
       " 'Sparta',\n",
       " 'Pride',\n",
       " ')',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'into',\n",
       " 'the',\n",
       " 'Western',\n",
       " 'Sector',\n",
       " 'in',\n",
       " '2006',\n",
       " '.',\n",
       " 'The',\n",
       " 'Mapogo',\n",
       " 'lions',\n",
       " 'followed',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'trend',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Sabi',\n",
       " 'Sand',\n",
       " 'Reserve',\n",
       " 'of',\n",
       " 'mega',\n",
       " 'pride',\n",
       " 'male',\n",
       " 'lion',\n",
       " 'coalitions',\n",
       " '.',\n",
       " 'The',\n",
       " 'five',\n",
       " 'related',\n",
       " 'brothers',\n",
       " 'were',\n",
       " 'sired',\n",
       " 'by',\n",
       " 'a',\n",
       " 'similar',\n",
       " 'mega',\n",
       " 'pride',\n",
       " 'coalition',\n",
       " 'of',\n",
       " 'five',\n",
       " 'male',\n",
       " 'lions',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'In',\n",
       " 'their',\n",
       " 'quest',\n",
       " 'to',\n",
       " 'dominate',\n",
       " 'the',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'six',\n",
       " 'lions',\n",
       " 'killed',\n",
       " 'approximately',\n",
       " '40',\n",
       " 'other',\n",
       " 'lions',\n",
       " 'which',\n",
       " 'included',\n",
       " 'many',\n",
       " 'cubs',\n",
       " ',',\n",
       " 'females',\n",
       " ',',\n",
       " 'and',\n",
       " 'rival',\n",
       " 'adult',\n",
       " 'males',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " '.The',\n",
       " 'oldest',\n",
       " 'Mapogo',\n",
       " 'male',\n",
       " ',',\n",
       " 'Makulu',\n",
       " ',',\n",
       " 'is',\n",
       " 'believed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'unrelated',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'five',\n",
       " 'lions',\n",
       " '.',\n",
       " 'The',\n",
       " 'story',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'original',\n",
       " 'Sparta',\n",
       " 'pride',\n",
       " 'lost',\n",
       " 'a',\n",
       " 'male',\n",
       " 'sub-adult',\n",
       " 'of',\n",
       " '20',\n",
       " 'to',\n",
       " '21',\n",
       " 'months',\n",
       " 'of',\n",
       " 'age',\n",
       " 'in',\n",
       " 'May/June',\n",
       " '2000',\n",
       " 'and',\n",
       " 'in',\n",
       " 'July',\n",
       " '2000',\n",
       " ',',\n",
       " 'this',\n",
       " 'male',\n",
       " 'of',\n",
       " 'about',\n",
       " 'the',\n",
       " 'same',\n",
       " 'age',\n",
       " 'latched',\n",
       " 'on',\n",
       " 'to',\n",
       " 'the',\n",
       " 'original',\n",
       " 'pride',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'result',\n",
       " ',',\n",
       " 'Makulu',\n",
       " 'was',\n",
       " 'naturally',\n",
       " 'bigger',\n",
       " 'in',\n",
       " 'size',\n",
       " 'than',\n",
       " 'his',\n",
       " 'fellow',\n",
       " 'brothers',\n",
       " '.',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'Though',\n",
       " 'not',\n",
       " 'readily',\n",
       " 'accepted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'lionesses',\n",
       " ',',\n",
       " 'the',\n",
       " 'West',\n",
       " 'Street',\n",
       " 'Males',\n",
       " 'tolerated',\n",
       " 'him',\n",
       " 'and',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'kill',\n",
       " 'him',\n",
       " ',',\n",
       " 'even',\n",
       " 'though',\n",
       " 'typically',\n",
       " ',',\n",
       " 'intruding',\n",
       " 'males',\n",
       " 'of',\n",
       " 'his',\n",
       " 'age',\n",
       " 'would',\n",
       " 'be',\n",
       " 'chased',\n",
       " 'off',\n",
       " 'or',\n",
       " 'killed',\n",
       " '.',\n",
       " 'Field',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'a',\n",
       " 'likely',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'his',\n",
       " 'acceptance',\n",
       " 'into',\n",
       " 'the',\n",
       " 'pride',\n",
       " 'was',\n",
       " 'because',\n",
       " 'he',\n",
       " 'may',\n",
       " 'have',\n",
       " 'been',\n",
       " 'the',\n",
       " 'offspring',\n",
       " 'of',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'West',\n",
       " 'Street',\n",
       " 'Males',\n",
       " 'and',\n",
       " 'a',\n",
       " 'lioness',\n",
       " 'from',\n",
       " 'another',\n",
       " 'pride',\n",
       " '(',\n",
       " 'therefore',\n",
       " 'making',\n",
       " 'him',\n",
       " 'the',\n",
       " 'Mapogos',\n",
       " \"'\",\n",
       " 'half',\n",
       " 'brother',\n",
       " ')',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " '.In',\n",
       " 'the',\n",
       " 'first',\n",
       " 'months',\n",
       " 'of',\n",
       " '2006',\n",
       " ',',\n",
       " 'the',\n",
       " 'five',\n",
       " 'subadult',\n",
       " 'lions',\n",
       " 'and',\n",
       " 'Makulu',\n",
       " 'left',\n",
       " 'their',\n",
       " 'pride',\n",
       " '.',\n",
       " 'They',\n",
       " 'now',\n",
       " 'had',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'but',\n",
       " 'by',\n",
       " 'sticking',\n",
       " 'together',\n",
       " 'they',\n",
       " 'increased',\n",
       " 'their',\n",
       " 'survival',\n",
       " 'chances',\n",
       " '.',\n",
       " 'Whilst',\n",
       " 'living',\n",
       " 'among',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'the',\n",
       " 'lions',\n",
       " 'learned',\n",
       " 'to',\n",
       " 'be',\n",
       " 'successful',\n",
       " 'hunters',\n",
       " '.',\n",
       " 'As',\n",
       " 'they',\n",
       " 'grew',\n",
       " 'in',\n",
       " 'size',\n",
       " 'and',\n",
       " 'experience',\n",
       " ',',\n",
       " 'they',\n",
       " 'were',\n",
       " 'able',\n",
       " 'to',\n",
       " 'take',\n",
       " 'down',\n",
       " 'large',\n",
       " 'prey',\n",
       " 'such',\n",
       " 'as',\n",
       " 'hippos',\n",
       " ',',\n",
       " 'young',\n",
       " 'rhinos',\n",
       " ',',\n",
       " 'and',\n",
       " 'even',\n",
       " 'giraffes',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'Dave',\n",
       " 'Salmoni',\n",
       " ',',\n",
       " 'successfully',\n",
       " 'taking',\n",
       " 'down',\n",
       " 'cape',\n",
       " 'buffalo',\n",
       " 'was',\n",
       " 'their',\n",
       " \"'key\",\n",
       " 'to',\n",
       " 'success',\n",
       " \"'\",\n",
       " '.',\n",
       " 'During',\n",
       " 'the',\n",
       " 'buffalo',\n",
       " 'hunts',\n",
       " ',',\n",
       " 'Kinky',\n",
       " 'Tail',\n",
       " '(',\n",
       " 'also',\n",
       " 'called',\n",
       " 'Shaka',\n",
       " ')',\n",
       " 'and',\n",
       " 'Mr.',\n",
       " 'T',\n",
       " '(',\n",
       " 'also',\n",
       " 'called',\n",
       " 'Satan',\n",
       " ')',\n",
       " 'were',\n",
       " 'often',\n",
       " 'observed',\n",
       " 'being',\n",
       " 'more',\n",
       " 'aggressive',\n",
       " 'in',\n",
       " 'bringing',\n",
       " 'down',\n",
       " 'the',\n",
       " 'buffalo',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## POS tagging and chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are eight parts of speech in the English language: noun, pronoun, verb, adjective, adverb, preposition, conjunction, and interjection. The part of speech indicates how the word functions in meaning as well as grammatically within the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### it is a method of tagging individual words on the basis of it's parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Mapogo', 'NNP'),\n",
       " ('coalition', 'NN'),\n",
       " ('originated', 'VBD'),\n",
       " ('from', 'IN'),\n",
       " ('Mala', 'NNP'),\n",
       " ('Mala', 'NNP'),\n",
       " ('from', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('called', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('“', 'NNP'),\n",
       " ('Eyrefield', 'NNP'),\n",
       " ('Pride', 'NNP'),\n",
       " ('”', 'NNP'),\n",
       " ('(', '('),\n",
       " ('Sparta', 'NNP'),\n",
       " ('Pride', 'NNP'),\n",
       " (')', ')'),\n",
       " ('and', 'CC'),\n",
       " ('moved', 'VBN'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Western', 'JJ'),\n",
       " ('Sector', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('2006', 'CD'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('Mapogo', 'NNP'),\n",
       " ('lions', 'NNS'),\n",
       " ('followed', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('recent', 'JJ'),\n",
       " ('trend', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Sabi', 'NNP'),\n",
       " ('Sand', 'NNP'),\n",
       " ('Reserve', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('mega', 'JJ'),\n",
       " ('pride', 'NN'),\n",
       " ('male', 'NN'),\n",
       " ('lion', 'NN'),\n",
       " ('coalitions', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('five', 'CD'),\n",
       " ('related', 'JJ'),\n",
       " ('brothers', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('sired', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('similar', 'JJ'),\n",
       " ('mega', 'JJ'),\n",
       " ('pride', 'NN'),\n",
       " ('coalition', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('five', 'CD'),\n",
       " ('male', 'JJ'),\n",
       " ('lions', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('[', '$'),\n",
       " ('4', 'CD'),\n",
       " (']', 'NN'),\n",
       " ('In', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('quest', 'JJS'),\n",
       " ('to', 'TO'),\n",
       " ('dominate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('area', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('six', 'CD'),\n",
       " ('lions', 'NNS'),\n",
       " ('killed', 'VBD'),\n",
       " ('approximately', 'RB'),\n",
       " ('40', 'CD'),\n",
       " ('other', 'JJ'),\n",
       " ('lions', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('included', 'VBD'),\n",
       " ('many', 'JJ'),\n",
       " ('cubs', 'NNS'),\n",
       " (',', ','),\n",
       " ('females', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('rival', 'JJ'),\n",
       " ('adult', 'NN'),\n",
       " ('males', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('[', '$'),\n",
       " ('5', 'CD'),\n",
       " (']', 'NNP'),\n",
       " ('.The', 'NNP'),\n",
       " ('oldest', 'JJS'),\n",
       " ('Mapogo', 'NNP'),\n",
       " ('male', 'NN'),\n",
       " (',', ','),\n",
       " ('Makulu', 'NNP'),\n",
       " (',', ','),\n",
       " ('is', 'VBZ'),\n",
       " ('believed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('unrelated', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('five', 'CD'),\n",
       " ('lions', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('story', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('original', 'JJ'),\n",
       " ('Sparta', 'NNP'),\n",
       " ('pride', 'NN'),\n",
       " ('lost', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('male', 'JJ'),\n",
       " ('sub-adult', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('20', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('21', 'CD'),\n",
       " ('months', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('age', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('May/June', 'NNP'),\n",
       " ('2000', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('in', 'IN'),\n",
       " ('July', 'NNP'),\n",
       " ('2000', 'CD'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('male', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('age', 'NN'),\n",
       " ('latched', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('original', 'JJ'),\n",
       " ('pride', 'NN'),\n",
       " ('.', '.'),\n",
       " ('As', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('result', 'NN'),\n",
       " (',', ','),\n",
       " ('Makulu', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('naturally', 'RB'),\n",
       " ('bigger', 'JJR'),\n",
       " ('in', 'IN'),\n",
       " ('size', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('fellow', 'JJ'),\n",
       " ('brothers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('[', '$'),\n",
       " ('6', 'CD'),\n",
       " (']', 'NNP'),\n",
       " ('Though', 'NNP'),\n",
       " ('not', 'RB'),\n",
       " ('readily', 'RB'),\n",
       " ('accepted', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lionesses', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('West', 'NNP'),\n",
       " ('Street', 'NNP'),\n",
       " ('Males', 'NNP'),\n",
       " ('tolerated', 'VBD'),\n",
       " ('him', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('did', 'VBD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('kill', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " (',', ','),\n",
       " ('even', 'RB'),\n",
       " ('though', 'IN'),\n",
       " ('typically', 'RB'),\n",
       " (',', ','),\n",
       " ('intruding', 'VBG'),\n",
       " ('males', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('age', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('chased', 'VBN'),\n",
       " ('off', 'RP'),\n",
       " ('or', 'CC'),\n",
       " ('killed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Field', 'NNP'),\n",
       " ('experts', 'NNS'),\n",
       " ('believe', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('likely', 'JJ'),\n",
       " ('reason', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('acceptance', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('pride', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('because', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('offspring', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('West', 'NNP'),\n",
       " ('Street', 'NNP'),\n",
       " ('Males', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('lioness', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('another', 'DT'),\n",
       " ('pride', 'NN'),\n",
       " ('(', '('),\n",
       " ('therefore', 'IN'),\n",
       " ('making', 'VBG'),\n",
       " ('him', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('Mapogos', 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " ('half', 'NN'),\n",
       " ('brother', 'NN'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('[', '$'),\n",
       " ('7', 'CD'),\n",
       " (']', 'NNP'),\n",
       " ('.In', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('2006', 'CD'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('five', 'CD'),\n",
       " ('subadult', 'NN'),\n",
       " ('lions', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('Makulu', 'NNP'),\n",
       " ('left', 'VBD'),\n",
       " ('their', 'PRP$'),\n",
       " ('pride', 'NN'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('now', 'RB'),\n",
       " ('had', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('fight', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('themselves', 'PRP'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('by', 'IN'),\n",
       " ('sticking', 'VBG'),\n",
       " ('together', 'RB'),\n",
       " ('they', 'PRP'),\n",
       " ('increased', 'VBD'),\n",
       " ('their', 'PRP$'),\n",
       " ('survival', 'NN'),\n",
       " ('chances', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Whilst', 'NNP'),\n",
       " ('living', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('themselves', 'PRP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('lions', 'NNS'),\n",
       " ('learned', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('successful', 'JJ'),\n",
       " ('hunters', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('As', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('grew', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('size', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('experience', 'NN'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('down', 'RP'),\n",
       " ('large', 'JJ'),\n",
       " ('prey', 'NN'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('hippos', 'NN'),\n",
       " (',', ','),\n",
       " ('young', 'JJ'),\n",
       " ('rhinos', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('giraffes', 'NN'),\n",
       " ('.', '.'),\n",
       " ('According', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('Dave', 'NNP'),\n",
       " ('Salmoni', 'NNP'),\n",
       " (',', ','),\n",
       " ('successfully', 'RB'),\n",
       " ('taking', 'VBG'),\n",
       " ('down', 'RP'),\n",
       " ('cape', 'NN'),\n",
       " ('buffalo', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('their', 'PRP$'),\n",
       " (\"'key\", 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('success', 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " ('.', '.'),\n",
       " ('During', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('buffalo', 'NN'),\n",
       " ('hunts', 'NNS'),\n",
       " (',', ','),\n",
       " ('Kinky', 'NNP'),\n",
       " ('Tail', 'NNP'),\n",
       " ('(', '('),\n",
       " ('also', 'RB'),\n",
       " ('called', 'VBN'),\n",
       " ('Shaka', 'NNP'),\n",
       " (')', ')'),\n",
       " ('and', 'CC'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('T', 'NNP'),\n",
       " ('(', '('),\n",
       " ('also', 'RB'),\n",
       " ('called', 'VBN'),\n",
       " ('Satan', 'NNP'),\n",
       " (')', ')'),\n",
       " ('were', 'VBD'),\n",
       " ('often', 'RB'),\n",
       " ('observed', 'VBN'),\n",
       " ('being', 'VBG'),\n",
       " ('more', 'RBR'),\n",
       " ('aggressive', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('bringing', 'VBG'),\n",
       " ('down', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('buffalo', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags=nltk.pos_tag(nltk.word_tokenize(data))\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chunking \n",
    "\n",
    "After using parts of speech, Chunking can be used to make data more structured by giving a specific set of rules. Chunking is also known as shallow parser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "Stop words are such words which are very common in occurrence such as ‘a’,’an’,’the’, ‘at’ etc. We ignore such words during the preprocessing part since they do not give any important information and would just take additional space. We can make our custom list of stop words as well if we want. Different libraries have different stop words list. Let’s see the stop words list for NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list=stopwords.words('english')\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we also have punctuations which we can ignore like stopwords\n",
    "import string\n",
    "punct_list=string.punctuation\n",
    "punct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Mapogo',\n",
       " 'coalition',\n",
       " 'originated',\n",
       " 'Mala',\n",
       " 'Mala',\n",
       " 'called',\n",
       " '“',\n",
       " 'Eyrefield',\n",
       " 'Pride',\n",
       " '”',\n",
       " 'Sparta',\n",
       " 'Pride',\n",
       " 'moved',\n",
       " 'Western',\n",
       " 'Sector',\n",
       " '2006',\n",
       " 'The',\n",
       " 'Mapogo',\n",
       " 'lions',\n",
       " 'followed',\n",
       " 'recent',\n",
       " 'trend',\n",
       " 'Sabi',\n",
       " 'Sand',\n",
       " 'Reserve',\n",
       " 'mega',\n",
       " 'pride',\n",
       " 'male',\n",
       " 'lion',\n",
       " 'coalitions',\n",
       " 'The',\n",
       " 'five',\n",
       " 'related',\n",
       " 'brothers',\n",
       " 'sired',\n",
       " 'similar',\n",
       " 'mega',\n",
       " 'pride',\n",
       " 'coalition',\n",
       " 'five',\n",
       " 'male',\n",
       " 'lions',\n",
       " '4',\n",
       " 'In',\n",
       " 'quest',\n",
       " 'dominate',\n",
       " 'area',\n",
       " 'six',\n",
       " 'lions',\n",
       " 'killed',\n",
       " 'approximately',\n",
       " '40',\n",
       " 'lions',\n",
       " 'included',\n",
       " 'many',\n",
       " 'cubs',\n",
       " 'females',\n",
       " 'rival',\n",
       " 'adult',\n",
       " 'males',\n",
       " '5',\n",
       " '.The',\n",
       " 'oldest',\n",
       " 'Mapogo',\n",
       " 'male',\n",
       " 'Makulu',\n",
       " 'believed',\n",
       " 'unrelated',\n",
       " 'five',\n",
       " 'lions',\n",
       " 'The',\n",
       " 'story',\n",
       " 'original',\n",
       " 'Sparta',\n",
       " 'pride',\n",
       " 'lost',\n",
       " 'male',\n",
       " 'sub-adult',\n",
       " '20',\n",
       " '21',\n",
       " 'months',\n",
       " 'age',\n",
       " 'May/June',\n",
       " '2000',\n",
       " 'July',\n",
       " '2000',\n",
       " 'male',\n",
       " 'age',\n",
       " 'latched',\n",
       " 'original',\n",
       " 'pride',\n",
       " 'As',\n",
       " 'result',\n",
       " 'Makulu',\n",
       " 'naturally',\n",
       " 'bigger',\n",
       " 'size',\n",
       " 'fellow',\n",
       " 'brothers',\n",
       " '6',\n",
       " 'Though',\n",
       " 'readily',\n",
       " 'accepted',\n",
       " 'lionesses',\n",
       " 'West',\n",
       " 'Street',\n",
       " 'Males',\n",
       " 'tolerated',\n",
       " \"n't\",\n",
       " 'kill',\n",
       " 'even',\n",
       " 'though',\n",
       " 'typically',\n",
       " 'intruding',\n",
       " 'males',\n",
       " 'age',\n",
       " 'would',\n",
       " 'chased',\n",
       " 'killed',\n",
       " 'Field',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'likely',\n",
       " 'reason',\n",
       " 'acceptance',\n",
       " 'pride',\n",
       " 'may',\n",
       " 'offspring',\n",
       " 'one',\n",
       " 'West',\n",
       " 'Street',\n",
       " 'Males',\n",
       " 'lioness',\n",
       " 'another',\n",
       " 'pride',\n",
       " 'therefore',\n",
       " 'making',\n",
       " 'Mapogos',\n",
       " 'half',\n",
       " 'brother',\n",
       " '7',\n",
       " '.In',\n",
       " 'first',\n",
       " 'months',\n",
       " '2006',\n",
       " 'five',\n",
       " 'subadult',\n",
       " 'lions',\n",
       " 'Makulu',\n",
       " 'left',\n",
       " 'pride',\n",
       " 'They',\n",
       " 'fight',\n",
       " 'sticking',\n",
       " 'together',\n",
       " 'increased',\n",
       " 'survival',\n",
       " 'chances',\n",
       " 'Whilst',\n",
       " 'living',\n",
       " 'among',\n",
       " 'lions',\n",
       " 'learned',\n",
       " 'successful',\n",
       " 'hunters',\n",
       " 'As',\n",
       " 'grew',\n",
       " 'size',\n",
       " 'experience',\n",
       " 'able',\n",
       " 'take',\n",
       " 'large',\n",
       " 'prey',\n",
       " 'hippos',\n",
       " 'young',\n",
       " 'rhinos',\n",
       " 'even',\n",
       " 'giraffes',\n",
       " 'According',\n",
       " 'Dave',\n",
       " 'Salmoni',\n",
       " 'successfully',\n",
       " 'taking',\n",
       " 'cape',\n",
       " 'buffalo',\n",
       " \"'key\",\n",
       " 'success',\n",
       " 'During',\n",
       " 'buffalo',\n",
       " 'hunts',\n",
       " 'Kinky',\n",
       " 'Tail',\n",
       " 'also',\n",
       " 'called',\n",
       " 'Shaka',\n",
       " 'Mr.',\n",
       " 'T',\n",
       " 'also',\n",
       " 'called',\n",
       " 'Satan',\n",
       " 'often',\n",
       " 'observed',\n",
       " 'aggressive',\n",
       " 'bringing',\n",
       " 'buffalo']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lets tokenize the data afetr cleaning it\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words_list=stopwords.words('english')\n",
    "punct_list=string.punctuation\n",
    "\n",
    "clean_data=[]\n",
    "for word in nltk.word_tokenize(data):\n",
    "    if word not in stop_words_list:\n",
    "        if word not in punct_list:\n",
    "            clean_data.append(word)\n",
    "    \n",
    "clean_data    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "Many words that are used in a sentence are not always used in their basic form but are used as per the rules of grammar e.g.\n",
    "\n",
    "running ---> run (base word)\n",
    "\n",
    "runs    ---> run (base word)    \n",
    "\n",
    "ran     ---> run (base word)\n",
    "\n",
    "Although, the underlying meaning will be same but form of the base word changes to preserve the correct grammatical meaning.\n",
    "\n",
    "Stemming and Lemmatization are basically used to bring such words to their basic forms, so that the words with same base are treated as same words rather than treated differently.\n",
    "\n",
    "The only difference in Stemming and Lemmatization is the way in which they change the word to its base form.\n",
    "\n",
    "* Stemming\n",
    "\n",
    "Stemming means mapping a group of words to the same stem by removing prefixes or suffixes without giving any value to the “grammatical meaning” of the stem formed after the process.\n",
    "\n",
    "e.g.\n",
    "\n",
    "computation --> comput\n",
    "\n",
    "computer --> comput \n",
    "\n",
    "hobbies --> hobbi\n",
    "\n",
    "We can see that stemming tries to bring the word back to their base word but the base word may or may not have correct grammatical meanings.\n",
    "\n",
    "There are typically two types of stemmers available in NLTK package.\n",
    "1)\tPorter Stemmer \n",
    "2)\tLancaster Stemmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "**************************\n",
      "lancaster stemmer\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "**************************\n",
      "Snowball stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "Snowball = SnowballStemmer(\"english\")\n",
    "print('Porter stemmer')\n",
    "print(porter.stem(\"hobby\"))\n",
    "print(porter.stem(\"hobbies\"))\n",
    "print(porter.stem(\"computer\"))\n",
    "print(porter.stem(\"computation\"))\n",
    "print(\"**************************\")  \n",
    "print('lancaster stemmer')\n",
    "print(lancaster.stem(\"hobby\"))\n",
    "print(lancaster.stem(\"hobbies\"))\n",
    "print(lancaster.stem(\"computer\"))\n",
    "print(porter.stem(\"computation\"))\n",
    "print(\"**************************\")  \n",
    "print('Snowball stemmer')\n",
    "print(Snowball.stem(\"hobby\"))\n",
    "print(Snowball.stem(\"hobbies\"))\n",
    "print(Snowball.stem(\"computer\"))\n",
    "print(Snowball.stem(\"computation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was go to the offic on my bike when i saw a car pass by hit the tree .\n",
      "i was going to the off on my bik when i saw a car pass by hit the tre .\n",
      "I wa go to the offic on my bike when i saw a car pass by hit the tree .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I was going to the office on my bike when i saw a car passing by hit the tree.\"\n",
    "token = list(nltk.word_tokenize(sentence))\n",
    "\n",
    "token = nltk.word_tokenize(sentence)\n",
    "\n",
    "for stemmer in (Snowball,lancaster,porter):\n",
    "    stemm=[stemmer.stem(t) for t in token]\n",
    "    print(\" \".join(stemm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lemmatization\n",
    "\n",
    "\n",
    "Lemmatization also does the same thing as stemming and try to bring a word to its base form, but unlike stemming it do keep in account the actual meaning of the base word i.e. the base word belongs to any specific language. The ‘base word’ is known as ‘Lemma’.\n",
    "\n",
    "We use WordNet Lemmatizer for Lemmatization in nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "runner\n",
      "run\n",
      "ran\n"
     ]
    }
   ],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('running'))\n",
    "print(lemma.lemmatize('runner'))\n",
    "print(lemma.lemmatize('runs'))\n",
    "print(lemma.lemmatize('ran'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition(NER)\n",
    "\n",
    "In chunking, we read that we can set rules to keep different POS tags under one sinlge user defined tag. One such form of chunking in NLP is known as Named Entity Recognition.\n",
    "\n",
    "In NER, we try to group entities like people, places, countries, things etc. together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Aswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  officially/RB\n",
      "  the/DT\n",
      "  (ORGANIZATION Republic/NNP)\n",
      "  of/IN\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  country/NN\n",
      "  in/IN\n",
      "  (GPE South/NNP Asia/NNP))\n"
     ]
    }
   ],
   "source": [
    "word=nltk.word_tokenize(' India, officially the Republic of India, is a country in South Asia')\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "ner=nltk.ne_chunk(pos_tag)\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorization (Word Embedding)\n",
    "\n",
    "Word vectorization is the process of mapping words to a set of real numbers or vectors. This is done to process the given words using machine learning techniques and extract relevant information from them such that it can be used in further predicting words. Vectorization is done by comparing a given word to the corpus(collection) of the available words.\n",
    "There are many different methods used for vectorizing a given set of words. let's see some of the mosed popular ones:\n",
    "\n",
    "### Count Vectorizer\n",
    "\n",
    "Count vectorizer uses two of the following models as the base to vectorize the given words on the basis of frequency of words.\n",
    "\n",
    "#### Bag of Words Model\n",
    "BOW model is used in NLP to represent the given text/sentence/document as a collection (bag) of words without giving any importance to grammar or the occurrence order of the words. It keeps the account of frequency of the words in the text document, which can be used as features in many models.\n",
    "\n",
    "Let’s understand this with an example:\n",
    "\n",
    "Text1 = “I went to have a cup of coffee but I ended up having lunch with her.”\n",
    "\n",
    "Text2 = “I don’t understand, what is the problem here?”\n",
    "\n",
    "BOW1 = {I :2, went : 1, to : 1,have : 1, a : 1, cup: 1, of :1, coffee : 1, but :1, ended : 1, up :1,having : 1, with :1, her :1}\n",
    "\n",
    "BOW2 = {I : 1, don’t : 1, understand:1, what : 1 , is :1, the : 1, problem : 1, here : 1}\n",
    "\n",
    "BOW is mainly used for feature selection. The above dictionary is converted as a list with only the frequency terms there and on that basis, weights are given to the most occurring terms. But the “stop words” are the most frequent words that appears in raw document. Thus, having a word with high frequency count doesn’t mean that the word is as important. To resolve this problem, “Tf-idf” was introduced. We will discuss about it later.\n",
    "\n",
    "#### n-gram model\n",
    "\n",
    "As discussed in bag of words model, BOW model doesn’t keep the sequence of words in a given text, only the frequency of words matters. It doesn’t take into account the context of the given sentence, or care for grammatical rules such as verb is following a proper noun in the given text.n-gram model is used in such cases to keep the context of the given text intact. N-gram is the sequence of n words from a given text/document.\n",
    "\n",
    "When, n= 1, we call it a “unigram”.\n",
    "\n",
    "             n=2, it is called a “bigram”. \n",
    "             \n",
    "             n=3, it is called a “trigram”.\n",
    "And so on.\n",
    "\n",
    "Let’s understand this with an example:\n",
    "\n",
    "Text1 = “I went to have a cup of coffee but I ended up having lunch with her.”\n",
    "\n",
    "* Unigram \n",
    "\n",
    "[I, went, to, have, a, cup, of, coffee, but, I, ended, up, having, lunch, with, her]\n",
    "\n",
    "* Bi-gram\n",
    "\n",
    "[I went], [went to],[to have],[have a],[a cup],[cup f],[of coffee],[coffee but],[but I],[I ended],[ended up],\n",
    "[up having],[having lunch],[lunch with],[with her]\n",
    "\n",
    "* Tri-gram\n",
    "\n",
    "[I went to], [went to have], [to have a], [have a cup],[ a cup of], [cup of coffee],[ of coffee but],[ coffee but I],[but I ended],[I ended up],[ended up having],[up having lunch],[having lunch with],[lunch with her].\n",
    "\n",
    "Note: We can clearly see that BOW model is nothing but n-gram model when n=1.\n",
    "\n",
    "Skip-grams\n",
    "\n",
    "Skip grams are type of n-grams where the words are not necessarily in the same order as are in the given text i.e. some words can be skipped. \n",
    "Example:\n",
    "\n",
    "Text2 = “I don’t understand, what is the problem here?”\n",
    "\n",
    "1-skip 2-grams (we have to make 2-gram while skipping 1 word)\n",
    "\n",
    "[I understand, don’t what, understand is, what the, is problem, the here].\n",
    "\n",
    "\n",
    "Let's see the implementation of Count vectorizer in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram  : ['an', 'example', 'gram', 'is', 'of', 'this']\n",
      "2-gram  : ['an example', 'example of', 'is an', 'of gram', 'this is']\n",
      "3-gram  : ['an example of', 'example of gram', 'is an example', 'this is an']\n",
      "4-gram  : ['an example of gram', 'is an example of', 'this is an example']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "string = [\"This is an example of n-gram!\"]\n",
    "vect1=CountVectorizer(ngram_range=(1,1))\n",
    "vect1.fit_transform(string)\n",
    "vect2 = CountVectorizer(ngram_range=(2,2))\n",
    "vect2.fit_transform(string)\n",
    "vect3 = CountVectorizer(ngram_range=(3,3))\n",
    "vect3.fit_transform(string)\n",
    "vect4 = CountVectorizer(ngram_range=(4,4))\n",
    "vect4.fit_transform(string)\n",
    "print(\"1-gram  :\",vect1.get_feature_names())\n",
    "print(\"2-gram  :\",vect2.get_feature_names())\n",
    "print(\"3-gram  :\",vect3.get_feature_names())\n",
    "print(\"4-gram  :\",vect4.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
     ]
    }
   ],
   "source": [
    "## Bag Of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "string = [\"This is an example of bag of words!\"]\n",
    "vect1 = CountVectorizer()\n",
    "vect1.fit_transform(string)\n",
    "print(\"bag of words :\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf (Term frequency–Inverse document frequency)\n",
    "\n",
    "Wikipedia definition:  ” Tf-Idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The Tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. Tf–idf is one of the most popular term-weighting schemes today.”\n",
    "\n",
    "\n",
    "### Term Frequency\n",
    "It is simply the frequency in which a word appears in a document in comparison to the total number words in the document. Mathematically given as:\n",
    "\n",
    "Term frequency = (Number of times a word appears in the document) / (Total number of words in the document)\n",
    "\n",
    "### Inverse Document Frequency\n",
    "\n",
    "Term frequency has a disadvantage that it tends to give higher weights to words with higher frequency. In such cases words like ‘a’, ‘the’, ‘in’, ’of’ etc. appears more in the documents than other regular words. Thus, more important words are wrongly given lower weights as their frequency is less.\n",
    " To tackle this problem IDF was introduced. IDF decreases the weights of such high frequency terms and increases the weight of terms with rare occurrence. Mathematically it is given as:\n",
    " \n",
    "Inverse Document Frequency = log [(Number of documents)/(Number of documents the word appears in)]   \n",
    "\n",
    "note: [log has base 2]\n",
    "\n",
    "\n",
    "*Tf-Idf Score = Term frequency * Inverse Document Frequency*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'be', 'can', 'confusing', 'example', 'how', 'idf', 'is', 'it', 'see', 'this', 'we', 'will', 'works']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "doc= [\"This is an example.\",\"We will see how it works.\",\"IDF can be confusing\"]\n",
    "tfidf=TfidfVectorizer(smooth_idf=False)\n",
    "tfidf.fit_transform(doc)\n",
    "print(tfidf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>be</th>\n",
       "      <th>can</th>\n",
       "      <th>confusing</th>\n",
       "      <th>example</th>\n",
       "      <th>how</th>\n",
       "      <th>idf</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>see</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "      <th>works</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    an   be  can  confusing  example       how  idf   is        it       see  \\\n",
       "0  0.5  0.0  0.0        0.0      0.5  0.000000  0.0  0.5  0.000000  0.000000   \n",
       "1  0.0  0.0  0.0        0.0      0.0  0.408248  0.0  0.0  0.408248  0.408248   \n",
       "2  0.0  0.5  0.5        0.5      0.0  0.000000  0.5  0.0  0.000000  0.000000   \n",
       "\n",
       "   this        we      will     works  \n",
       "0   0.5  0.000000  0.000000  0.000000  \n",
       "1   0.0  0.408248  0.408248  0.408248  \n",
       "2   0.0  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vector=tfidf.fit_transform(doc)\n",
    "df=pd.DataFrame(doc_vector.todense(),columns=tfidf.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "         0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.40824829, 0.        , 0.        , 0.40824829, 0.40824829,\n",
       "         0.        , 0.40824829, 0.40824829, 0.40824829],\n",
       "        [0.        , 0.5       , 0.5       , 0.5       , 0.        ,\n",
       "         0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
